{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Jin Choi: Methodology, Project administration\n",
    "- Sujin Kim: Conceptualization, Visualization\n",
    "- Rowoon Lee: Background research, Software\n",
    "- Idhant Kuma: Data curation, Writing original draft \n",
    "- Yechan Park: Analysis, experimental investigation, Writing review & editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a statistically significant correlation between the global production rate of plastics and key indicators of global warming, such as atmospheric CO₂ concentration, fossil fuel consumption, and global average temperature anomalies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rapid growth of global plastic production over recent decades has raised increasing concern due to its environmental and climate impacts. Since the 1950s, plastic production has increased from almost zero to hundreds of millions of metric tons per year, largely driven by industrialization and rising consumer demand [1]. Because most plastics are produced from fossil fuels, their manufacturing and disposal require large amounts of energy and result in greenhouse gas emissions. As a result, plastic production is closely connected to broader patterns of fossil fuel use and industrial activity.\n",
    "Long-term observations show that atmospheric carbon dioxide (CO₂) concentrations have risen steadily since the late 1950s. Measurements collected by the National Oceanic and Atmospheric Administration (NOAA) indicate that current CO₂ levels are significantly higher than pre-industrial values and continue to increase each year [2]. This rise is mainly caused by the widespread burning of fossil fuels and other human activities, and it is strongly linked to global warming. Increasing CO₂ concentrations are associated with other major climate indicators, including rising global temperature anomalies, reflecting an enhanced greenhouse effect in Earth’s atmosphere.\n",
    "Scientific assessments by the Intergovernmental Panel on Climate Change (IPCC) provide strong evidence that human-driven increases in greenhouse gases have caused widespread warming across the climate system. The IPCC Sixth Assessment Report explains that excess heat trapped by greenhouse gases has been absorbed largely by the oceans since the mid-20th century, leading to accelerating glacier and ice-sheet melt and rising global sea levels [3]. These observed changes closely follow long-term increases in fossil fuel consumption and industrial production, suggesting that other fossil-fuel-intensive activities may exhibit similar relationships with climate indicators.\n",
    "Global temperature records further support this warming trend. Data from NASA’s Goddard Institute for Space Studies show that recent decades are significantly warmer than the mid-20th century average, indicating a clear and persistent rise in global temperature anomalies [4]. Because plastics are derived from fossil fuels and contribute to greenhouse gas emissions throughout their lifecycle, examining the statistical relationship between global plastic production and key climate indicators. Atmospheric CO₂ concentrations and global temperature anomalies can help clarify how industrial production aligns with observed global warming trends.\n",
    "\n",
    "References\n",
    "1. Our World in Data. Global Plastics Production. https://ourworldindata.org/grapher/global-plastics-production\n",
    "2. NOAA Global Monitoring Laboratory. Trends in Atmospheric Carbon Dioxide. https://gml.noaa.gov/ccgg/trends/\n",
    "3. IPCC. (2021). Climate Change 2021: The Physical Science Basis, Chapter 9. https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-9/\n",
    "4. NASA Goddard Institute for Space Studies. GISTEMP Surface Temperature Analysis. https://data.giss.nasa.gov/gistemp/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that there is a statistically significant positive correlation between global plastic production levels and indicators of global warming, including atmospheric CO₂ concentration, fossil fuel consumption, and global average temperature anomalies. This relationship is expected because plastic production is highly dependent on fossil fuels and contributes to greenhouse gas emissions throughout its lifecycle. As plastic production increases steadily over time, we anticipate upward trends in the climate variables as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "#### Dataset 1: Global Plastic Production\n",
    "\n",
    "The Global plastic production dataset is a series of plastic production measured in tonnes from 1950 to 2019. It contains information mainly from Geyer et al. about one global value per year while demonstrating 5% of annual growth rate from 2016 to 2018. \n",
    "\n",
    "**Link to the dataset**: https://ourworldindata.org/grapher/global-plastics-production\n",
    "\n",
    "**Number of observations**: 70 \n",
    "\n",
    "**Number of variables**: 4: `entity`, `code`, `year` and the measured value column for plastics production in tonnes \n",
    "\n",
    "**Description of the variables most relevant to this project**: \n",
    "`Year`: the observation year\n",
    "`Entity`: the geographic unit \n",
    "`Plastic production`: “annual production of polymer resin and fibers in tonnes”\n",
    "\n",
    "**Descriptions of any shortcomings this dataset has with respect to the project**: \n",
    "This dataset only provide global totals not a country/region breakdown\n",
    "Values from this dataset is a bit mixed and later year values aren’t directly measured from a single consistent system\n",
    "The amount of production doesn’t directly related ot the outcome of waste/pollution\n",
    "This dataset lack confidence intervals/measurement uncertainty  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2: Global Monthly Atmospheric CO₂ Data\n",
    "\n",
    "**Link to the Dataset**: https://gml.noaa.gov/ccgg/trends/gl_data.html\n",
    "\n",
    "**Number of Observations**: ~800+ monthly global observations\n",
    "\n",
    "**Number of Variables**: Year, month, decimal date, monthly mean CO₂ (ppm), deseasonalized trend, number of days measured\n",
    "\n",
    "**Variables most relevant to this project**: year — calendar year, month — month of observation, average — monthly global CO₂ concentration (ppm), trend — seasonally adjusted global CO₂ concentration\n",
    "\n",
    "**Shortcomings**: \n",
    "- Still observational (no causation)\n",
    "- Aggregated global average may hide regional variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3: Global Land–Ocean Temperature Anomalies (NASA GISTEMP) \n",
    "\n",
    "**Source:** NASA Goddard Institute for Space Studies (GISS), GISTEMP Surface Temperature Analysis.  \n",
    "**File:** `GLB.Ts+dSST.csv` (downloaded from [data.giss.nasa.gov/gistemp](https://data.giss.nasa.gov/gistemp/)).\n",
    "\n",
    "**Important metrics and units:**  \n",
    "Each row is one year (1880–present). All temperature values are **anomalies** in degrees Celsius (°C): the deviation from the **1951–1980 global mean** (the baseline). For example, `0.5` means 0.5°C warmer than that baseline; `-0.2` means 0.2°C cooler. In practice, early decades (e.g. 1880s–1970s) often show negative or near-zero anomalies (cooler or similar to the baseline), while recent decades (e.g. 1990s onward) consistently show positive anomalies—recent years often range from about +0.5°C to over +1.2°C, reflecting well-documented global warming. The column **`J-D`** (January–December) is the annual mean land–ocean temperature anomaly and is the main variable we use to correlate with plastic production and other climate indicators. Monthly columns (Jan–Dec) and seasonal columns (e.g. DJF, MAM, JJA, SON) are also present; we focus on `Year` and `J-D` for consistency with the project’s research question.\n",
    "\n",
    "**Concerns and limitations:**  \n",
    "The data are global aggregates from a well-established scientific product, so there is no sample bias in the usual sense. Missing values are encoded as `***`, mainly for (1) the most recent partial year (e.g. 2026) when the year is incomplete, and (2) some derived columns (e.g. D-N, DJF) in early years where the seasonal definition does not apply. We restrict to years with a non-missing `J-D` so that analyses use only complete annual values. Because all time series in the project share a common upward trend over time, we will later need to be careful not to overinterpret correlation as causation. The checkpoint focuses on obtaining and cleaning this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 4: Global Annual Mean CO₂ Data\n",
    "\n",
    "**Link to the Dataset**: https://gml.noaa.gov/ccgg/trends/gl_data.html\n",
    "\n",
    "**Number of Observations**: ~60+ annual observations\n",
    "\n",
    "**Number of Variables**: Year, annual mean CO₂ (ppm)\n",
    "\n",
    "**Variables most relevant to this project**: year — calendar year, month — month of observation, average — monthly global CO₂ concentration (ppm), trend — seasonally adjusted global CO₂ concentration\n",
    "\n",
    "**Shortcomings**: \n",
    "- Annual averaging removes seasonal detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:  33%|███▎      | 1/3 [00:00<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: global-plastics-production.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:  67%|██████▋   | 2/3 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: co2_mm_gl.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress: 100%|██████████| 3/3 [00:00<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: co2_annmean_gl.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://ourworldindata.org/grapher/global-plastics-production.csv', 'filename':'global-plastics-production.csv'},\n",
    "    {\n",
    "        'url': 'https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_gl.csv',\n",
    "        'filename': 'co2_mm_gl.csv'\n",
    "    },\n",
    "    {\n",
    "        'url': 'https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_annmean_gl.csv',\n",
    "        'filename': 'co2_annmean_gl.csv'\n",
    "    }\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Global Plastic Production Dataset (World Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "INTERIM_DIR = Path(\"data/01-interim\")\n",
    "PROCESSED_DIR = Path(\"data/02-processed\")\n",
    "for d in [RAW_DIR, INTERIM_DIR, PROCESSED_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_PATH = RAW_DIR / \"global-plastics-production.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw data from: data/00-raw/global-plastics-production.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Annual plastic production between 1950 and 2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>OWID_WRL</td>\n",
       "      <td>1950</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World</td>\n",
       "      <td>OWID_WRL</td>\n",
       "      <td>1951</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World</td>\n",
       "      <td>OWID_WRL</td>\n",
       "      <td>1952</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World</td>\n",
       "      <td>OWID_WRL</td>\n",
       "      <td>1953</td>\n",
       "      <td>3000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World</td>\n",
       "      <td>OWID_WRL</td>\n",
       "      <td>1954</td>\n",
       "      <td>3000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entity      Code  Year  Annual plastic production between 1950 and 2019\n",
       "0  World  OWID_WRL  1950                                          2000000\n",
       "1  World  OWID_WRL  1951                                          2000000\n",
       "2  World  OWID_WRL  1952                                          2000000\n",
       "3  World  OWID_WRL  1953                                          3000000\n",
       "4  World  OWID_WRL  1954                                          3000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape (rows, cols): (69, 4)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "\n",
    "df_raw = pd.read_csv(RAW_PATH)\n",
    "print(\"Loaded raw data from:\", RAW_PATH)\n",
    "display(df_raw.head())\n",
    "print(\"Raw shape (rows, cols):\", df_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns: ['Entity', 'Code', 'Year', 'Annual plastic production between 1950 and 2019']\n",
      "\n",
      "Dtypes:\n",
      " Entity                                             object\n",
      "Code                                               object\n",
      "Year                                                int64\n",
      "Annual plastic production between 1950 and 2019     int64\n",
      "dtype: object\n",
      "Main production column: Annual plastic production between 1950 and 2019\n",
      "Duplicate Entity-Year rows: 0\n",
      "✅ Data is already in tidy long format (Entity-Year observations). No reshape needed.\n"
     ]
    }
   ],
   "source": [
    "# 2) Tidy check\n",
    "\n",
    "# Tidy criteria: each variable is a column; each observation is a row.\n",
    "print(\"\\nColumns:\", df_raw.columns.tolist())\n",
    "print(\"\\nDtypes:\\n\", df_raw.dtypes)\n",
    "\n",
    "# Expect OWID style: Entity, Year, and one value column\n",
    "required = {\"Entity\", \"Year\"}\n",
    "if not required.issubset(df_raw.columns):\n",
    "    raise ValueError(f\"Expected at least {required}, but got {df_raw.columns.tolist()}\")\n",
    "\n",
    "# Identify numeric value columns besides Year\n",
    "numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "value_candidates = [c for c in numeric_cols if c != \"Year\"]\n",
    "if len(value_candidates) == 0:\n",
    "    raise ValueError(\"No numeric value column found besides Year.\")\n",
    "value_col = value_candidates[0]  # main metric column\n",
    "print(\"Main production column:\", value_col)\n",
    "\n",
    "# Check if one row per Entity-Year\n",
    "dup_entity_year = df_raw.duplicated(subset=[\"Entity\", \"Year\"]).sum()\n",
    "print(\"Duplicate Entity-Year rows:\", dup_entity_year)\n",
    "print(\"✅ Data is already in tidy long format (Entity-Year observations). No reshape needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset size:\n",
      "Rows: 69\n",
      "Columns: 4\n",
      "Unique entities: 1\n",
      "Year range: 1950 to 2019\n"
     ]
    }
   ],
   "source": [
    "# 3) Dataset size\n",
    "\n",
    "print(\"\\nDataset size:\")\n",
    "print(\"Rows:\", len(df_raw))\n",
    "print(\"Columns:\", df_raw.shape[1])\n",
    "print(\"Unique entities:\", df_raw[\"Entity\"].nunique())\n",
    "print(\"Year range:\", int(df_raw[\"Year\"].min()), \"to\", int(df_raw[\"Year\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missingness by column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual plastic production between 1950 and 2019</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 missing_count  missing_pct\n",
       "Entity                                                       0          0.0\n",
       "Code                                                         0          0.0\n",
       "Year                                                         0          0.0\n",
       "Annual plastic production between 1950 and 2019              0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with any missing values: 0\n",
      "✅ No missing values detected → missingness does not appear to be an issue for this dataset.\n"
     ]
    }
   ],
   "source": [
    "# 4) Missingness\n",
    "\n",
    "missing_count = df_raw.isna().sum()\n",
    "missing_pct = (missing_count / len(df_raw) * 100).round(2)\n",
    "missing_report = pd.DataFrame({\"missing_count\": missing_count, \"missing_pct\": missing_pct}).sort_values(\n",
    "    \"missing_count\", ascending=False\n",
    ")\n",
    "print(\"\\nMissingness by column:\")\n",
    "display(missing_report)\n",
    "\n",
    "rows_with_missing = df_raw[df_raw.isna().any(axis=1)]\n",
    "print(\"Rows with any missing values:\", rows_with_missing.shape[0])\n",
    "\n",
    "if rows_with_missing.shape[0] > 0:\n",
    "    print(\"\\nWhere missingness happens (by Year):\")\n",
    "    display(rows_with_missing[\"Year\"].value_counts().sort_index())\n",
    "\n",
    "    print(\"\\nWhere missingness happens (by Entity):\")\n",
    "    display(rows_with_missing[\"Entity\"].value_counts().head(15))\n",
    "\n",
    "    print(\"\\nInterpretation: If missingness clusters in specific years/entities, it is likely systematic (not random-looking).\")\n",
    "else:\n",
    "    print(\"✅ No missing values detected → missingness does not appear to be an issue for this dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suspicious/outlier rows flagged: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Annual plastic production between 1950 and 2019</th>\n",
       "      <th>flag_negative</th>\n",
       "      <th>flag_duplicate_entity_year</th>\n",
       "      <th>flag_iqr_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Entity, Code, Year, Annual plastic production between 1950 and 2019, flag_negative, flag_duplicate_entity_year, flag_iqr_outlier]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interim flagged dataset to: data/01-interim/global_plastics_production_flagged.csv\n"
     ]
    }
   ],
   "source": [
    "# 5) Flag outliers / suspicious entries\n",
    "# ----------------------------\n",
    "df_flagged = df_raw.copy()\n",
    "\n",
    "# Suspicious: negative production values\n",
    "df_flagged[\"flag_negative\"] = df_flagged[value_col] < 0\n",
    "\n",
    "# Suspicious: duplicate Entity-Year rows\n",
    "df_flagged[\"flag_duplicate_entity_year\"] = df_flagged.duplicated(subset=[\"Entity\", \"Year\"], keep=False)\n",
    "\n",
    "# Outlier review flag via IQR \n",
    "q1, q3 = df_flagged[value_col].quantile([0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "df_flagged[\"flag_iqr_outlier\"] = (df_flagged[value_col] < lo) | (df_flagged[value_col] > hi)\n",
    "\n",
    "suspicious = df_flagged[df_flagged[[\"flag_negative\",\"flag_duplicate_entity_year\",\"flag_iqr_outlier\"]].any(axis=1)]\n",
    "print(\"\\nSuspicious/outlier rows flagged:\", suspicious.shape[0])\n",
    "display(suspicious.head(20))\n",
    "\n",
    "# Save interim (optional)\n",
    "INTERIM_PATH = INTERIM_DIR / \"global_plastics_production_flagged.csv\"\n",
    "df_flagged.to_csv(INTERIM_PATH, index=False)\n",
    "print(\"Saved interim flagged dataset to:\", INTERIM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows missing key fields: 0\n",
      "Removed negative rows: 0\n",
      "\n",
      "Cleaned shape: (69, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Year</th>\n",
       "      <th>Annual plastic production between 1950 and 2019</th>\n",
       "      <th>flag_negative</th>\n",
       "      <th>flag_duplicate_entity_year</th>\n",
       "      <th>flag_iqr_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>1950</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World</td>\n",
       "      <td>1951</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World</td>\n",
       "      <td>1952</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World</td>\n",
       "      <td>1953</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World</td>\n",
       "      <td>1954</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entity  Year  Annual plastic production between 1950 and 2019  \\\n",
       "0  World  1950                                        2000000.0   \n",
       "1  World  1951                                        2000000.0   \n",
       "2  World  1952                                        2000000.0   \n",
       "3  World  1953                                        3000000.0   \n",
       "4  World  1954                                        3000000.0   \n",
       "\n",
       "   flag_negative  flag_duplicate_entity_year  flag_iqr_outlier  \n",
       "0          False                       False             False  \n",
       "1          False                       False             False  \n",
       "2          False                       False             False  \n",
       "3          False                       False             False  \n",
       "4          False                       False             False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6) Clean data \n",
    "\n",
    "# We drop rows missing key fields (Entity/Year/value) because imputing aggregate annual production would be speculative and could bias trends.\n",
    "df_clean = df_flagged.copy()\n",
    "\n",
    "# Remove duplicate Entity-Year (keep first)\n",
    "df_clean = df_clean.drop_duplicates(subset=[\"Entity\", \"Year\"], keep=\"first\")\n",
    "\n",
    "# Drop rows missing key fields\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=[\"Entity\", \"Year\", value_col])\n",
    "print(\"Dropped rows missing key fields:\", before - len(df_clean))\n",
    "\n",
    "# Remove negative values (set to NaN then drop)\n",
    "neg_before = (df_clean[value_col] < 0).sum()\n",
    "df_clean.loc[df_clean[value_col] < 0, value_col] = np.nan\n",
    "df_clean = df_clean.dropna(subset=[value_col])\n",
    "print(\"Removed negative rows:\", int(neg_before))\n",
    "\n",
    "# Ensure Year is int\n",
    "df_clean[\"Year\"] = df_clean[\"Year\"].astype(int)\n",
    "\n",
    "# Keep core columns + flags (clean output)\n",
    "df_clean = df_clean[[\"Entity\", \"Year\", value_col, \"flag_negative\", \"flag_duplicate_entity_year\", \"flag_iqr_outlier\"]]\n",
    "\n",
    "print(\"\\nCleaned shape:\", df_clean.shape)\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed clean dataset to: data/02-processed/global_plastics_production_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# 7) Write final processed dataset\n",
    "\n",
    "PROCESSED_PATH = PROCESSED_DIR / \"global_plastics_production_clean.csv\"\n",
    "df_clean.to_csv(PROCESSED_PATH, index=False)\n",
    "print(\"Saved processed clean dataset to:\", PROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Global Monthly Atmospheric CO₂ Data\n",
    "This dataset contains monthly global atmospheric carbon dioxide (CO₂) measurements provided by NOAA’s Global Monitoring Laboratory. Each row represents one month of globally averaged CO₂ concentration. The dataset includes variables such as year, month, decimal date, average CO₂ concentration, deseasonalized trend, and number of days measured.\n",
    "\n",
    "CO₂ concentration is measured in parts per million (ppm), which represents how many CO₂ molecules exist per one million molecules of air. Monthly data allows us to observe both long-term upward trends and seasonal fluctuations in global atmospheric CO₂ levels. The seasonal variation reflects natural plant growth cycles, while the long-term increase reflects human-related greenhouse gas emissions.\n",
    "\n",
    "A limitation of this dataset is that, although it represents global averages, it does not capture regional differences in CO₂ levels. Additionally, this dataset shows trends and correlations but does not establish causation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (563, 7)\n",
      "\n",
      "Column names and dtypes:\n",
      "year             int64\n",
      "month            int64\n",
      "decimal        float64\n",
      "average        float64\n",
      "average_unc    float64\n",
      "trend          float64\n",
      "trend_unc      float64\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>decimal</th>\n",
       "      <th>average</th>\n",
       "      <th>average_unc</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>1979.042</td>\n",
       "      <td>336.56</td>\n",
       "      <td>0.11</td>\n",
       "      <td>335.92</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>1979.125</td>\n",
       "      <td>337.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>336.26</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>1979.208</td>\n",
       "      <td>337.88</td>\n",
       "      <td>0.11</td>\n",
       "      <td>336.51</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>1979.292</td>\n",
       "      <td>338.32</td>\n",
       "      <td>0.13</td>\n",
       "      <td>336.72</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>5</td>\n",
       "      <td>1979.375</td>\n",
       "      <td>338.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>336.71</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month   decimal  average  average_unc   trend  trend_unc\n",
       "0  1979      1  1979.042   336.56         0.11  335.92       0.09\n",
       "1  1979      2  1979.125   337.29         0.09  336.26       0.09\n",
       "2  1979      3  1979.208   337.88         0.11  336.51       0.09\n",
       "3  1979      4  1979.292   338.32         0.13  336.72       0.10\n",
       "4  1979      5  1979.375   338.26         0.04  336.71       0.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "year           0\n",
      "month          0\n",
      "decimal        0\n",
      "average        0\n",
      "average_unc    0\n",
      "trend          0\n",
      "trend_unc      0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>decimal</th>\n",
       "      <th>average</th>\n",
       "      <th>average_unc</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>563.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2001.959147</td>\n",
       "      <td>6.490231</td>\n",
       "      <td>2002.458334</td>\n",
       "      <td>375.844725</td>\n",
       "      <td>0.104636</td>\n",
       "      <td>375.846110</td>\n",
       "      <td>0.064938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.554035</td>\n",
       "      <td>3.450385</td>\n",
       "      <td>13.555698</td>\n",
       "      <td>25.761809</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>25.737807</td>\n",
       "      <td>0.017569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1979.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1979.042000</td>\n",
       "      <td>334.370000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>335.920000</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1990.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1990.750000</td>\n",
       "      <td>354.355000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>354.450000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2002.458000</td>\n",
       "      <td>372.840000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>372.300000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2014.166500</td>\n",
       "      <td>396.745000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>396.570000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2025.875000</td>\n",
       "      <td>426.940000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>426.630000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year       month      decimal     average  average_unc  \\\n",
       "count   563.000000  563.000000   563.000000  563.000000   563.000000   \n",
       "mean   2001.959147    6.490231  2002.458334  375.844725     0.104636   \n",
       "std      13.554035    3.450385    13.555698   25.761809     0.031044   \n",
       "min    1979.000000    1.000000  1979.042000  334.370000     0.030000   \n",
       "25%    1990.000000    3.500000  1990.750000  354.355000     0.080000   \n",
       "50%    2002.000000    6.000000  2002.458000  372.840000     0.100000   \n",
       "75%    2014.000000    9.000000  2014.166500  396.745000     0.120000   \n",
       "max    2025.000000   12.000000  2025.875000  426.940000     0.260000   \n",
       "\n",
       "            trend   trend_unc  \n",
       "count  563.000000  563.000000  \n",
       "mean   375.846110    0.064938  \n",
       "std     25.737807    0.017569  \n",
       "min    335.920000    0.030000  \n",
       "25%    354.450000    0.050000  \n",
       "50%    372.300000    0.060000  \n",
       "75%    396.570000    0.080000  \n",
       "max    426.630000    0.120000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "co2_monthly = pd.read_csv(\n",
    "    \"data/00-raw/co2_mm_gl.csv\",\n",
    "    comment=\"#\"\n",
    ")\n",
    "\n",
    "print(\"Shape (rows, columns):\", co2_monthly.shape)\n",
    "\n",
    "print(\"\\nColumn names and dtypes:\")\n",
    "print(co2_monthly.dtypes)\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(co2_monthly.head())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(co2_monthly.isna().sum())\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(co2_monthly.describe())\n",
    "\n",
    "print(\"\\nDuplicate rows:\", co2_monthly.duplicated().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Global Land–Ocean Temperature Anomalies (NASA GISTEMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (147, 19)\n",
      "\n",
      "Column names and dtypes:\n",
      "Year      int64\n",
      "Jan     float64\n",
      "Feb     float64\n",
      "Mar     float64\n",
      "Apr     float64\n",
      "May     float64\n",
      "Jun     float64\n",
      "Jul     float64\n",
      "Aug     float64\n",
      "Sep     float64\n",
      "Oct     float64\n",
      "Nov     float64\n",
      "Dec     float64\n",
      "J-D     float64\n",
      "D-N     float64\n",
      "DJF     float64\n",
      "MAM     float64\n",
      "JJA     float64\n",
      "SON     float64\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>J-D</th>\n",
       "      <th>D-N</th>\n",
       "      <th>DJF</th>\n",
       "      <th>MAM</th>\n",
       "      <th>JJA</th>\n",
       "      <th>SON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1880</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1881</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1882</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
       "0  1880 -0.19 -0.25 -0.10 -0.17 -0.11 -0.22 -0.19 -0.11 -0.15 -0.24 -0.23   \n",
       "1  1881 -0.21 -0.15  0.02  0.04  0.05 -0.20 -0.01 -0.04 -0.16 -0.22 -0.19   \n",
       "2  1882  0.15  0.13  0.04 -0.18 -0.15 -0.24 -0.17 -0.08 -0.15 -0.24 -0.17   \n",
       "3  1883 -0.30 -0.37 -0.13 -0.19 -0.18 -0.07 -0.08 -0.14 -0.22 -0.11 -0.25   \n",
       "4  1884 -0.14 -0.09 -0.37 -0.40 -0.34 -0.35 -0.31 -0.28 -0.27 -0.25 -0.34   \n",
       "\n",
       "    Dec   J-D   D-N   DJF   MAM   JJA   SON  \n",
       "0 -0.18 -0.18   NaN   NaN -0.13 -0.17 -0.21  \n",
       "1 -0.08 -0.10 -0.10 -0.18  0.04 -0.08 -0.19  \n",
       "2 -0.37 -0.12 -0.09  0.07 -0.10 -0.16 -0.19  \n",
       "3 -0.12 -0.18 -0.20 -0.35 -0.17 -0.10 -0.19  \n",
       "4 -0.31 -0.29 -0.27 -0.11 -0.37 -0.31 -0.29  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tidy check: one row per observation (year), one column per variable. No need to reshape.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 3.1 Load the dataset from data/00-raw/ ---\n",
    "# First row is a title line, so we skip it. Missing values are encoded as '***'.\n",
    "raw_path = 'data/00-raw/GLB.Ts+dSST.csv'\n",
    "temp_raw = pd.read_csv(raw_path, skiprows=1, na_values='***')\n",
    "\n",
    "print(\"Shape (rows, columns):\", temp_raw.shape)\n",
    "print(\"\\nColumn names and dtypes:\")\n",
    "print(temp_raw.dtypes)\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(temp_raw.head())\n",
    "\n",
    "# --- 3.2 Tidy format: one row per year, one column per variable → already tidy ---\n",
    "print(\"\\nTidy check: one row per observation (year), one column per variable. No need to reshape.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 (tidy) & 3.3 (size):** The dataset is already in tidy form: one row per year, one column per variable (year, monthly anomalies, annual J-D, seasonal indices). Below we verify the size (number of observations and variables) and then assess missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations (years): 147\n",
      "Number of variables: 19\n",
      "\n",
      "Missing values per column (only columns with any missing):\n",
      "Feb    1\n",
      "Mar    1\n",
      "Apr    1\n",
      "May    1\n",
      "Jun    1\n",
      "Jul    1\n",
      "Aug    1\n",
      "Sep    1\n",
      "Oct    1\n",
      "Nov    1\n",
      "Dec    1\n",
      "J-D    1\n",
      "D-N    2\n",
      "DJF    2\n",
      "MAM    1\n",
      "JJA    1\n",
      "SON    1\n",
      "dtype: int64\n",
      "\n",
      "Rows (years) with missing J-D: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>J-D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  J-D\n",
       "146  2026  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3.3 Demonstrate the size of the dataset ---\n",
    "print(\"Number of observations (years):\", len(temp_raw))\n",
    "print(\"Number of variables:\", len(temp_raw.columns))\n",
    "\n",
    "# --- 3.4 How much data is missing, where, and is it missing at random? ---\n",
    "print(\"\\nMissing values per column (only columns with any missing):\")\n",
    "missing_counts = temp_raw.isna().sum()\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Which years have missing J-D? (critical for our analysis)\n",
    "jd_missing = temp_raw[temp_raw['J-D'].isna()]\n",
    "print(\"\\nRows (years) with missing J-D:\", len(jd_missing))\n",
    "if len(jd_missing) > 0:\n",
    "    display(jd_missing[['Year', 'J-D']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missingness:** Missing values are not at random. They appear (1) in the most recent year when only partial months exist (e.g. 2026), and (2) in derived columns (D-N, DJF, etc.) for early years where the seasonal definition does not apply. For our analysis we only need `Year` and `J-D`; we will drop rows where `J-D` is missing so that every retained row has a valid annual anomaly. We do not fill missing values, since we need complete years for correlation with other annual datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5 Find and flag outliers or suspicious entries:** We check for extreme values in our key variable `J-D`. Temperature anomalies are physical measurements; unusually warm or cool years are real climate events, not data-entry errors. We flag them for review but do not remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years with lowest J-D (coldest relative to 1951-1980 baseline):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>J-D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1909</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1904</td>\n",
       "      <td>-0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1917</td>\n",
       "      <td>-0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1910</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1911</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   J-D\n",
       "29  1909 -0.50\n",
       "24  1904 -0.48\n",
       "37  1917 -0.47\n",
       "30  1910 -0.45\n",
       "31  1911 -0.45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Years with highest J-D (warmest relative to baseline):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>J-D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2025</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2023</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year   J-D\n",
       "144  2024  1.28\n",
       "145  2025  1.19\n",
       "143  2023  1.17\n",
       "136  2016  1.01\n",
       "140  2020  1.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusion: All flagged values are plausible (historical cold spells and recent warming). We keep all rows; no outliers removed.\n"
     ]
    }
   ],
   "source": [
    "# Ensure J-D is numeric for this check (in case we ran cells out of order)\n",
    "temp_raw['J-D'] = pd.to_numeric(temp_raw['J-D'], errors='coerce')\n",
    "jd_valid = temp_raw.dropna(subset=['J-D'])\n",
    "\n",
    "# Flag extremes: years with lowest and highest annual anomaly\n",
    "print(\"Years with lowest J-D (coldest relative to 1951-1980 baseline):\")\n",
    "display(jd_valid.nsmallest(5, 'J-D')[['Year', 'J-D']])\n",
    "print(\"\\nYears with highest J-D (warmest relative to baseline):\")\n",
    "display(jd_valid.nlargest(5, 'J-D')[['Year', 'J-D']])\n",
    "print(\"\\nConclusion: All flagged values are plausible (historical cold spells and recent warming). We keep all rows; no outliers removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropping rows with missing J-D: 146\n",
      "Year range in cleaned data: 1880 – 2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>J-D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2023</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2025</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year   J-D\n",
       "136  2016  1.01\n",
       "137  2017  0.92\n",
       "138  2018  0.85\n",
       "139  2019  0.98\n",
       "140  2020  1.01\n",
       "141  2021  0.85\n",
       "142  2022  0.90\n",
       "143  2023  1.17\n",
       "144  2024  1.28\n",
       "145  2025  1.19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3.6 Clean the data: deal with missingness ---\n",
    "# Choice: we use dropna(subset=['J-D']) (not fillna). Justification: we need complete annual\n",
    "# values to merge with other yearly datasets; filling would impute values we cannot verify.\n",
    "temp_raw['J-D'] = pd.to_numeric(temp_raw['J-D'], errors='coerce')\n",
    "temp_clean = temp_raw.dropna(subset=['J-D']).copy()\n",
    "temp_clean = temp_clean.astype({'Year': 'int64'})\n",
    "\n",
    "print(\"Rows after dropping rows with missing J-D:\", len(temp_clean))\n",
    "print(\"Year range in cleaned data:\", temp_clean['Year'].min(), \"–\", temp_clean['Year'].max())\n",
    "temp_clean[['Year', 'J-D']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7 Save final wrangled data:** We load from `data/00-raw/` (done above). We do not write an intermediate stage to `data/01-interim/` because the only change is dropping one incomplete year. The final, fully wrangled table (Year + annual anomaly) is written to `data/02-processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/02-processed/global_temp_anomaly_giss.csv\n",
      "Shape: (146, 2)\n",
      "\n",
      "Summary statistics for key variables (Year and temp_anomaly_C):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>temp_anomaly_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1952.500000</td>\n",
       "      <td>0.080274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.290661</td>\n",
       "      <td>0.403674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1880.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1916.250000</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1952.500000</td>\n",
       "      <td>-0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1988.750000</td>\n",
       "      <td>0.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>1.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year  temp_anomaly_C\n",
       "count   146.000000      146.000000\n",
       "mean   1952.500000        0.080274\n",
       "std      42.290661        0.403674\n",
       "min    1880.000000       -0.500000\n",
       "25%    1916.250000       -0.200000\n",
       "50%    1952.500000       -0.030000\n",
       "75%    1988.750000        0.317500\n",
       "max    2025.000000        1.280000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subset to columns needed for the project; write final data to data/02-processed/\n",
    "processed = temp_clean[['Year', 'J-D']].rename(columns={'J-D': 'temp_anomaly_C'})\n",
    "os.makedirs('data/02-processed', exist_ok=True)\n",
    "out_path = 'data/02-processed/global_temp_anomaly_giss.csv'\n",
    "processed.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved to\", out_path)\n",
    "print(\"Shape:\", processed.shape)\n",
    "\n",
    "# --- 4. Summary statistics for important variables ---\n",
    "print(\"\\nSummary statistics for key variables (Year and temp_anomaly_C):\")\n",
    "display(processed.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint summary — Data cleaning (Dataset #3)**  \n",
    "- **How clean is the data?** The raw file is well-structured and mostly clean. The only issues are (1) a title row we skip on read, (2) missing values encoded as `***` (incomplete or inapplicable values), and (3) one incomplete year (2026) with missing `J-D`.  \n",
    "- **What did we do to get it usable?** We loaded from `data/00-raw/` (3.1), confirmed the data are already tidy (3.2), reported size (3.3), assessed missingness and showed it is systematic not random (3.4), flagged and reviewed extremes and kept them (3.5), dropped only rows with missing `J-D` and justified not filling (3.6), and wrote the final wrangled table to `data/02-processed/` (3.7). We did not fill missing values because we need complete annual values for merging.  \n",
    "- **Pre-processing for analysis:** We restricted to `Year` and annual mean anomaly (`temp_anomaly_C`) and saved that table for merging. No distributional transformations were required for this checkpoint; if we use parametric methods later, we may check normality of the anomaly series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Global Annual Mean CO₂ Data\n",
    "This dataset contains annual global mean atmospheric CO₂ concentrations provided by NOAA. Each row represents one year of globally averaged CO₂ levels. The dataset includes the calendar year and the annual mean CO₂ concentration (ppm).\n",
    "\n",
    "Annual data removes seasonal variation and highlights long-term trends more clearly. This makes it especially useful for comparing CO₂ levels with other yearly indicators, such as global plastic production or global temperature anomalies.\n",
    "\n",
    "A limitation of this dataset is that annual averaging removes seasonal detail, which may hide short-term fluctuations. Additionally, like the monthly dataset, it provides observational data and does not directly explain the causes of CO₂ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (46, 3)\n",
      "\n",
      "Column names and dtypes:\n",
      "year      int64\n",
      "mean    float64\n",
      "unc     float64\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>336.86</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>338.91</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>340.11</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982</td>\n",
       "      <td>340.85</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1983</td>\n",
       "      <td>342.53</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    mean   unc\n",
       "0  1979  336.86  0.10\n",
       "1  1980  338.91  0.07\n",
       "2  1981  340.11  0.08\n",
       "3  1982  340.85  0.03\n",
       "4  1983  342.53  0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "year    0\n",
      "mean    0\n",
      "unc     0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2001.500000</td>\n",
       "      <td>374.855435</td>\n",
       "      <td>0.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.422618</td>\n",
       "      <td>25.253197</td>\n",
       "      <td>0.016964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1979.000000</td>\n",
       "      <td>336.860000</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1990.250000</td>\n",
       "      <td>354.395000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2001.500000</td>\n",
       "      <td>371.575000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2012.750000</td>\n",
       "      <td>394.712500</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024.000000</td>\n",
       "      <td>422.800000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year        mean        unc\n",
       "count    46.000000   46.000000  46.000000\n",
       "mean   2001.500000  374.855435   0.065000\n",
       "std      13.422618   25.253197   0.016964\n",
       "min    1979.000000  336.860000   0.030000\n",
       "25%    1990.250000  354.395000   0.050000\n",
       "50%    2001.500000  371.575000   0.070000\n",
       "75%    2012.750000  394.712500   0.070000\n",
       "max    2024.000000  422.800000   0.100000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "co2_annual = pd.read_csv(\n",
    "    \"data/00-raw/co2_annmean_gl.csv\",\n",
    "    comment=\"#\"\n",
    ")\n",
    "\n",
    "print(\"Shape (rows, columns):\", co2_annual.shape)\n",
    "print(\"\\nColumn names and dtypes:\")\n",
    "print(co2_annual.dtypes)\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(co2_annual.head())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(co2_annual.isna().sum())\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(co2_annual.describe())\n",
    "\n",
    "print(\"\\nDuplicate rows:\", co2_annual.duplicated().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "\n",
    "The data used in this project are public, aggregated datasets from sources like Our World in Data, NOAA, NASA, and the IPCC, so there are no privacy concerns since no personal or individual data are included. The data are free to use for research and follow open data terms. However, there may be some bias in how the data were collected. For example, plastics production data rely on country and industry reports, which may be less accurate in regions with weaker reporting systems. Climate data may also reflect more measurements from developed countries, which could slightly bias global averages.\n",
    "Another issue is that all datasets show strong upward trends over time, which could make correlations look stronger than they really are. To handle this, the data will be checked for missing values and inconsistencies, and trends will be visualized before running any statistical tests. Results will be explained carefully, making it clear that correlation does not mean non-checked sources. When sharing results, the limits of the data will be clearly stated to avoid misleading conclusions or unfairly blaming specific groups or regions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team expectation 1: Communication\n",
    "* Primary communication method: discord chat and call \n",
    "* Response time usually within a day and everyone should answer the weekly group meeting call since we are all contributing to the proposal\n",
    "* If a deadline is within 48 hours, we aim to start at least 12 hours before the dead line\n",
    "* If someone is unavailable to answer the call or do the work, they have to notice the group as soon as possible\n",
    "\n",
    "Team expectation 2: Weekly Meeting Schedule \n",
    "* Meeting will be held every week usually wednesday around 3-5 pm since we know everyone is available during that period of time \n",
    "* Each meeting we discuss what to do by the deadline and what to expect, and plan for the next meeting\n",
    "* We use google doc to do the assignments and submit whoever is available\n",
    "\n",
    "Team expectation 3: Decision-making\n",
    "* During the team meeting, we go for the majority \n",
    "* Whoever is available can create the assignment document or submit the assignment\n",
    "* If a quick decision needs to be made, whoever answer the first gets the chance \n",
    "\n",
    "Team expectation 4: Equal Contribution\n",
    "* Everyone puts equal amount of time and effort to finish the assignment \n",
    "* We will use our Github page and google doc to work on most of our project \n",
    "* Everyone must contribute into the weekly meeting and has to let everyone know if something happens on the discord chat \n",
    "* Respect every member and make sure to keep the boundaries \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/30  |  1 PM | We checked group members and reached out for a group chat. Read and think about what to answer for the assignment where all the members read previous proposals and give a review of them.   | Discussed who will answer which portions and shared thoughts about two different previous proposal examples in order for us to do better.  | \n",
    "| 2/4  |  3 PM |  Think about which research question we want to work on. | Discuss which portion in the proposal each person wants to work on, and what to answer. | \n",
    "| 2/11  | 3 PM  | Prepare data we need for our research and keep collecting them. | Share the data we collected and the approaches we should take. Every member works on their assigned parts. |\n",
    "| 2/18  | 3 PM  | Combine the data and utilize them so we can use it on the project; we start using the EDA too.  | Review our work and the data collected. Check if there’s anything wrong with using EDA. |\n",
    "| 2/25  | 3 PM  | Finalize the project generally and start making the analysis for the project.  | Discuss what to include in the analysis and what to highlight. Everyone should participate and share their thoughts and ideas. Complete project check-in. |\n",
    "| 3/4  | 3 PM  | Complete the analysis and make the final draft of the project to see if there’s anything causing problems. | Discuss and make edits on the analysis and the contents generally. |\n",
    "| 3/18  | Before 11:59 PM  | Finish up and fix last minute errors and submit the project  | Submit the project and the surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
